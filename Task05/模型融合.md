# 模型融合

**模型融合（model ensemble）是什么**

Ensemble Learning是一组individual learner的组合

- 如果individual learner（基学习器）是同质，即都是决策树或都是SVM，成为base learner
- 如果individual learner异质，称为component learner

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/01.png)

**这里讲解一个上次没有说明的问题，即过拟合和欠拟合**

**模型状态**

分为**过拟合**和**欠拟合**。

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/02.jpeg)

而如何来判断一个模型是否过拟合呢？**学习曲线**

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/03.jpeg)

上图中左上图是欠拟合，其特点是随着训练样本的增多，模型的训练精度和泛化精度会较快的接近，然而精度的值却较低。可理解为选择了过于简单的模型，如本来是个二次曲线却用了线性来模拟，这样无论怎么增加训练样本，都不可能继续讲模拟结果精度提高。

而右上图是过拟合，其特点是由于选择了非常符合训练集的数据，随着训练样本的增多，模型训练结果的精度会维持到一个较高的水平，但是其泛化能力较差，泛化精度与训练精度相差较大。但是随着样本数据的增多，其泛化能力也在逐渐增强。

https://zhuanlan.zhihu.com/p/38171570

## 简单加权融合

- 回归

  算术平均：

  ![img](https://www.zhihu.com/equation?tex=pred%3D%5Calpha%2Apred_a%2B%281-%5Calpha%29pred_b)

  几何平均： 

  ![img](https://www.zhihu.com/equation?tex=pred%3Dpred_%7Ba%7D%5E%7B%5Cbeta%7D%5Ctimes+pred_%7Bb%7D%5E%7B1-%5Cbeta%7D)

- 分类

  投票

  对于分类问题的预测，我们通常使用的是投票法。假设我们的预测类别是

  ![img](https://www.zhihu.com/equation?tex=%5C%7Bc_1%2Cc_2%2C...%2Cc_K%5C%7D)

  ，对于任意一个预测样本$x$，我们的$T$个弱学习器的预测结果分别是

  ![img](https://www.zhihu.com/equation?tex=%28h_1%28x%29%2Ch_2%28x%29%2C...%2Ch_T%28x%29%29)

  。

  最简单的投票法是相对多数投票法（plurality voting），也就是我们常说的少数服从多数，也就是$T$个弱学习器的对样本$x$的预测结果中，数量最多的类别为最终的分类类别。如果不止一个类别获得最高票，则随机选择一个做最终类别。

  稍微复杂的投票法是绝对多数投票法（majority voting），也就是我们常说的要票过半数。在相对多数投票法的基础上，不光要求获得最高票，还要求票过半数。否则会拒绝预测。

  更加复杂的是加权投票法（weighted voting），和加权平均法一样，每个弱学习器的分类票数要乘以一个权重，最终将各个类别的加权票数求和，最大的值对应的类别为最终类别。

  链接：https://zhuanlan.zhihu.com/p/39920405

- 综合

  排序融合（排序后融合）

  log融合(取log在融合)

## boosting/bagging

### 在xgboost、adaboost、GBDT中已经用到

##### 集成学习

集成学习通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统、基于委员会的学习等。集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的泛化性能。下面从两个方面对集成学习进行简要介绍。

- 分类
  根据个体学习器的生成方式，目前的集成学习方法大致可以分为两大类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同时生成的并行化方法；前者的代表是Boosting，后者的代表是Bagging和随机森林。

- 结合策略
  对于基分类器最终的结合策略常见的方法有如下几种：

  - 平均法
    对于数值形输出，最常见的结合策略即为平均法：


$$
H(x)=\frac{1}{T}\sum_{i=1}^{T}h_{i}(x)
$$


  其中h_{i}(x)为基学习器的输出结果，H(x)为最终学习器的结果，T为基学习器的个数。

  - 加权平均法


$$
  H(x)=\sum_{i=1}^{T}w_{i}h_{i}(x)
$$


  其中w_{i}是个体学习器h_{i}的权重，通常要求$w_{i}\geqslant 0,\sum_{i=1}^{T}w_{i}=1$。显然，简单平均法是加权平均法令$w_{i}=1/T$的特例。

  - 投票法
    预测结果为得票最多的标记，若同时有多个标记获得相同的票数，则从中随机选取一个。
  - 学习法
    当训练数据很多时，可以通过另一个学习器来对所有基学习器产生结果的结合方法进行学习，这时候个体学习器称为初级学习器，用于结合的学习器成为次级学习器或元学习器。

#### Adaboost

#### 思想

AdaBoost是最著名的Boosting族算法。开始时，所有样本的权重相同，训练得到第一个基分类器。从第二轮开始，每轮开始前都先根据上一轮基分类器的分类效果调整每个样本的权重，上一轮分错的样本权重提高，分对的样本权重降低。之后根据新得到样本的权重指导本轮中的基分类器训练，即在考虑样本不同权重的情况下得到本轮错误率最低的基分类器。重复以上步骤直至训练到约定的轮数结束，每一轮训练得到一个基分类器。

可以想象到，远离边界（超平面）的样本点总是分类正确，而分类边界附近的样本点总是有大概率被弱分类器（基分类器）分错，所以权值会变高，即边界附近的样本点会在分类时得到更多的重视。

#### 举例

为了防止看到公式推导你(wo)就(zao)要(pao)跑(le)，我们先来通过例子让你明白AdaBoost的运作方式，这样从整体框架上有个印象，之后再进行公式的推导。例子所用的代码在文章最后给出。

首先对一些符号进行约定：

|                   符号                    |               含义               |
| :---------------------------------------: | :------------------------------: |
| D = \{(\vec{x_{i}}, y_{i}),\ i\in[1, m]\} |        训练集，共m个样本         |
|                     T                     |             训练轮数             |
|                 D_{t}(x)                  |      第t轮时样本的权重分布       |
|                   h_{t}                   |       第t轮得到的基分类器        |
|                \alpha_{t}                 |    第t轮得到的基分类器的权重     |
|               \epsilon_{t}                |        第t轮h_{t}的错误率        |
|                 P_{A}(D)                  | 强分类器A在数据集D上的最终准确率 |

接下来，给定下边的数据集D，我们用AdaBoost算法来学习得到一个强分类器

|  x   |  0   |  1   |  2   |  3   |  4   |  5   |  6   |  7   |  8   |  9   |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
|  y   |  1   |  1   |  1   |  -1  |  -1  |  -1  |  1   |  1   |  1   |  -1  |

数据集D共有10条数据，根据x的输入得到的y可以分类两类，即y=1与y=-1。我们每一轮使用最简单的决策树桩来构建基分类器，即每轮设定一个阈值$\theta$，只要x<$\theta$，就判定为正类(y=1)，x>$\theta$就判定为负类(y=-1)。

#### 第一轮

- $D_{1}(x)$
  因为是第一轮，故所有样本的权重相同：
  $$
  D_{1}(\vec{x})=\{\frac{1}{10},\frac{1}{10},\frac{1}{10},\frac{1}{10},\frac{1}{10},\frac{1}{10},\frac{1}{10},\frac{1}{10},\frac{1}{10},\frac{1}{10}\}
  $$

- $\theta$
  因为是离散数据，所以$\theta$可以依次取0.5，1.5，2.5，...，8.5来对x进行分类，这里可以有两种分类方法：

  - x<$\theta$时分为正类，x>$\theta$时分为负类，分类错误率对应$\epsilon_{t}^{1}$
  - x>$\theta$时分为正类，x<$\theta$时分为负类，分类错误率对应$\epsilon_{t}^{2}$

  最终要选择一个令$\epsilon_{1}$取得最小值的$\theta$与分类方法，这9个值在两种分类方法下，此层$h_{1}$的错误$\vec{\epsilon_{1}}$分别为：


$$
\vec{\epsilon_{1}^{1}}=\{0.5*\frac{1}{10}, 0.4*\frac{1}{10}, 0.3*\frac{1}{10}, 0.4*\frac{1}{10}, 0.5*\frac{1}{10}, \\ 0.6*\frac{1}{10}, 0.5*\frac{1}{10}, 0.4*\frac{1}{10}, 0.3*\frac{1}{10}\}\\ \vec{\epsilon_{1}^{2}}=\{0.5*\frac{1}{10}, 0.6*\frac{1}{10}, 0.7*\frac{1}{10}, 0.6*\frac{1}{10}, 0.5*\frac{1}{10}, \\ 0.4*\frac{1}{10}, 0.5*\frac{1}{10}, 0.6*\frac{1}{10}, 0.7*\frac{1}{10}\}
$$


可以看到$\vec{\epsilon_{1}^{1}}$中的$0.3*\frac{1}{10}$为最小值。对应的，我们取$\theta$为2.5（$\theta$为8.5亦可），使用第一种分类方法。则x为0，1，2的样本分为正类，都分对了；而之后的样本都被分为负类，分错了3个，所以总错误率为$3*\frac{1}{10}$。故此轮弱分类器的阈值\theta取2.5，分类方法取第一种。

- $\alpha_{1}$
  第一层基分类器$h_{1}$的权重$\alpha_{1}$的计算推到方法后面的推导部分再细说，此处只要知道通过如下的公式来计算即可：


$$
\alpha_{1}=\frac{1}{2}log\frac{1-\epsilon_{1}}{\epsilon_{1}}=0.4236
$$


- $H(x), P_{A}(D)$
  根据如下公式计算$H(x)$，此时T为1：


$$
H(x) = \sum_{t=1}^{T}\alpha_{t}h_{t}(x)\\ H(x) =\{0.424, 0.424, 0.424, -0.424, -0.424, -0.424, -0.424, -0.424, -0.424, -0.424\}\\ sign(H(x)) = \{1, 1, 1, -1, -1, -1, -1, -1, -1, -1\}
$$


整个模型（现在只有一个基分类器）的准确率为：


$$
P_{A}(D)=0.7
$$


至此第一轮的工作就结束了，可以看出被误分类样本的权值之和影响误差率，误差率影响基分类器在最终分类器中所占的权重。

#### 第二轮

- $D_{2}(x)$
  第一轮训练完成后对D_{1}(x)进行更新得到D_{2}(x)，更新公式的推导过程也是等到后边的推到部分再说，此处还是只要知道通过下边的公式来计算更新即可：

$$
D_{2}(x)=\frac{D_{1}(x){e}^{-\alpha_{1}y(x)h_{1}(x)}}{Z_{1}}\\
D_{2}(x)=\{0.071, 0.071, 0.071, 0.071, 0.071, 0.071, 0.167, 0.167, 0.167, 0.071\}
$$



上一轮中x=6、7、8的点分错了，可以看到这三个点在D_{2}中的权重变大了，而其余分类正确的点权重变小了。

- $\theta$
  我们依然对$\theta$依次取0.5, 1.5, ... , 8.5来对x进行分类，注意我们刚才已经得到了D_{2}(x)，样本权重的分布不再是第一轮全部相等的$\frac{1}{10}$了，如当$\theta$取0.5按第一种分类方法进行分类时,$\epsilon_{2}^{1}$计算方法如下：



$$
\epsilon_{2}^{1}(\theta=0.5) = 0*0.071+1*0.071+1*0.071+0*0.071+0*0.071+\\ 0*0.071+1*0.167+1*0.167+1*0.167+0*0.071\\ =0.643
$$


对所有\theta与分类方法都按照如上的步骤进行计算，则可得到$\vec{\epsilon_{2}^{1}}与\vec{\epsilon_{2}^{2}}$分别为：



$$
\vec{\epsilon_{2}^{1}}=\{0.643, 0.571, 0.5, 0.571, 0.643, 0.714, 0.548, 0.381, 0.214\}\\ \vec{\epsilon_{2}^{2}}=\{0.357, 0.429, 0.5, 0.429, 0.357, 0.286, 0.452, 0.619, 0.786\}
$$


可以看到$\vec{\epsilon_{2}^{1}}$中的0.214为最小值，故此轮弱分类器的阈值$\theta$取8.5，分类方法为第一种。

- $\alpha_{2}$
  依然使用如下公式进行计算：



$$
\alpha_{1}=\frac{1}{2}log\frac{1-\epsilon_{2}}{\epsilon_{2}}=0.6496
$$


- $H(x), P_{A}(D)$
  继续根据如下公式计算H(x)，此时T为2：

$$
H(x) = \sum_{t=1}^{T}\alpha_{t}h_{t}(x)\\ H(x) =\{1.073, 1.073, 1.073, 0.226, 0.226, 0.226, 0.226, 0.226, 0.226, -1.073\}\\ sign(H(x)) = \{1, 1, 1, 1, 1, 1, 1, 1, 1, -1\}
$$

整个模型（现在有两个基分类器）的准确率仍然为：

$$
P_{A}(D)=0.7
$$


至此第二轮的工作就结束了，下面我们继续使用上边的方式来看第三轮是否能将准确率提升。

#### 第三轮

- $D_{3}(x)$
  使用D_{2}(x)更新得到D_{3}(x)如下：



$$
D_{3}(x)=\{0.045, 0.045, 0.045, 0.167, 0.167, 0.167, 0.106, 0.106, 0.106, 0.045\}
$$


上一轮中x=3、4、5的点被分错，所以在$D_{3}$中的权重变大，其余分类正确的点权重变小。

- $\theta$
  继续使用之前的方法得到$\vec{\epsilon_{3}^{1}}与\vec{\epsilon_{3}^{2}}$分别为：



$$
\vec{\epsilon_{3}^{1}}=\{0.409, 0.364, 0.318, 0.485, 0.652, 0.818, 0.712, 0.606, 0.5\}\\ \vec{\epsilon_{3}^{2}}=\{0.591, 0.636, 0.682, 0.515, 0.348, 0.182, 0.288, 0.394, 0.5\}
$$


可以看到$\vec{\epsilon_{3}^{2}}$中的0.182为最小值，故此轮弱分类器的阈值$\theta$取5.5，分类方法为第二种。

- $\alpha_{2}$
  依然使用如下公式进行计算：



$$
\alpha_{1}=\frac{1}{2}log\frac{1-\epsilon_{2}}{\epsilon_{2}}=0.752
$$


- $H(x), P_{A}(D)$
  继续根据如下公式计算H(x)，此时T为3：



$$
H(x) = \sum_{t=1}^{T}\alpha_{t}h_{t}(x)\\ H(x) =\{0.321, 0.321, 0.321, -0.526, -0.526, -0.526, 0.978, 0.978, 0.978, -0.321\}\\ sign(H(x)) = \{1, 1, 1, -1, -1, -1, 1, 1, 1, -1\}
$$


整个模型（现在有三个基分类器）的准确率为：



P_{A}(D)=1



至此，我们只用了3个弱（基）分类器就在样本集D上得到了100%的准确率，总结一下：

- 在第t轮被分错的样本，在下一轮更新得到的$D_{t+1}(x)$中权值将被增大
- 在第t轮被分对的样本，在下一轮更新得到的$D_{t+1}(x)$中权值将被减小
- 所使用的决策树桩总是选取让错误率\epsilon_{t}（所有被h_{t}分类错误的样本在D_{t}(x)中对应的权值之和）最低的阈值来设计基本分类器
- 最终Adboost得到的H(x)为：



$$
sign(H(x))=sign(0.4236*h_{1}+0.6496*h_{2}+0.752*h_{3})
$$


#### 其他情况

上边的例子每一轮使用了最简单的决策树桩来得到基分类器，下面就几种常见的其他情况对基分类器的训练过程进行简单介绍，纯粹个人理解，如有错误之处请及时指出。

- 分类问题
  - 决策树桩
    见上例
  - 决策树
    每一个节点的选择过程都需要将$D_{t}(x)$考虑进去，即在定义损失函数的时候，考虑每一个样本被分错的代价（权重）
  - 逻辑回归
    阈值$\theta$的选取需令本层$\epsilon_{t}$取得最小值
- 回归问题
  - 按照$D_{t}(x)$的分布对原始数据集进行重新采样，利用采样后得到的新数据集再进行训练

#### 推导

AdaBoost算法可以认为是一种模型为加法模型、损失函数为指数函数、学习算法为前向分步算法的而分类学习方法。在对\alpha_{t}和D_{t}进行推导前，我们先对加法模型和前向分步算法进行简要介绍。

- 加法模型
  加法模型的定义如下：



$$
f(x)=\sum_{M}^{m=1}\beta_{m}b(x;\gamma_{m})
$$


其中，$b(x;\gamma_{m})$为基函数，$\beta_{m}$为基函数的系数，$\gamma_{m}$为基函数的参数。在给定训练数据及损失函数L(y, f(x))的条件下，学习加法模型f(x)成为经验风险极小化，即损失函数极小化的问题：



$$
\underset{\beta_{m},\gamma_{m}}{min}\sum_{i=1}^{N}L(y_{i},\sum_{M}^{m=1}\beta_{m}b(x;\gamma_{m}))
$$


这通常是一个极其复杂的优化问题，因为需要同时考虑所有基函数与其权重的选取来令目标最小化。

- 前向分步算法
  前向分步算法对加法模型的求解思路是：如果能够从前向后，每一步只学习一个基函数及其系数，逐步逼近优化目标，那么就可以简化优化的复杂度。即每步只需优化如下损失函数：



$$
\underset{\beta,\gamma}{min}\sum_{M}^{m=1}L(y_{i},\beta b(x;\gamma))
$$


这样，前向分步算法将同时求解所有步骤的$\beta_{m}、\gamma_{m}$的优化问题简化为逐次求解各个$\beta_{m}、\gamma_{m}$的优化问题。

- $\alpha_{t}$的推导过程
  AdaBoost算法是前向分布加法算法的特例。这时，模型是由基本分类器组成的加法模型，损失函数是指数函数。即此时的基函数为基分类器。AdaBoost的最终分类器为：



$$
H(x) = \sum_{t=1}^{T}\alpha_{t}h_{t}(x)
$$


损失函数为：



$$
L(y, H(x)) = e^{-yH(x)}
$$


上式即被称为指数损失函数，其中y是样本的真实类别。假设在第t轮迭代时有：



$$
H_{t}(x)=H_{t-1}(x)+\alpha_{t}h_{t}(x)
$$


目标是使得到的$\alpha_{t}和h_{t}(x)令L(y, H(x))$最小，即：



$$
(\alpha_{t},h_{t}(x))=\underset{\alpha_{t},h_{t}}{arg\ min}\sum_{i=1}^{N}e^{-y_{i}(H_{t-1}(x)+\alpha_{t}h_{t}(x))}\\ =\underset{\alpha_{t},h_{t}}{arg\ min}\sum_{i=1}^{N}\bar{w}_{ti}e^{-y_{i}\alpha_{t}h_{t}(x)}\\ h_{t}(x)^{*}=\underset{h_{t}(x)}{arg\ min}\sum_{i=1}^{N}\bar{w}_{ti}I(y_{i}\neq h_{t}(x))
$$
其中，$\bar{w}_{ti}=e^{-y_{i}H_{t-1}(x)}$。因为\bar{w}_{ti}既不依赖于 \alpha_{t}也不依赖于$h_{t}(x)$，所以与最小化无关。但它依赖于H_{t-1}(x)，会随着每一轮迭代而发生变化。第二个式子为令指数损失函数最小的h_{t}(x)^{*}，其中I(\cdot)为指示函数，此h_{t}(x)^{*}使第m轮加权训练数据分类的误差率得到了最小值。接下来我们对上边的第一个式子的右边进行一下简单变形：



$$
\sum_{i=1}^{N}\bar{w}_{ti}e^{y_{i}\alpha_{t}h_{t}(x_{i})}\\ =\sum_{y_{i}=h_{t}(x_{i})}\bar{w}_{ti}e^{-\alpha_{t}}+\sum_{y_{i}\neq h_{t}(x_{i})}\bar{w}_{ti}e^{\alpha_{t}}\\ =(e^{\alpha_{t}}-e^{-\alpha_{t}})\sum_{i=1}^{N}\bar{w}_{ti}I(y_{i}\neq h_{t}(x_{i}))+e^{-\alpha}\sum_{i=1}^{N}\bar{w}_{ti}
$$


将上式对\alpha_{t}求导并令导数为0，即可解得：



$$
\alpha_{t}^{*}=\frac{1}{2}log\frac{1-e_{t}}{e_{t}}
$$


上式即之前例子中所用到的\alpha_{t}的更新公式，其中，e_{t}为分类误差率：



$$
e_{t}=\frac{\sum_{i=1}^{N}\bar{w}_{ti}I(y_{i}\neq h_{t}(x_{i}))}{\sum_{i=1}^{N}\bar{w}_{ti}}\\ =\sum_{i=1}^{N}w_{ti}I(y_{i}\neq h_{t}(x_{i}))
$$


由此可知，当$e_{t}\leqslant \frac{1}{2}$时，$\alpha_{t}\geqslant 0$，并且$\alpha_{t}$随着$e_{t}$的减小而增大，所以分类误差率越小的基分类器在最终分类器中的作用越大。

- $D_{t}$的推导过程
  接下来我们对D_{t}的更新公式进行推导。由之前推导过程中所得到的下边两个式子：



$$
H_{t}(x)=H_{t-1}(x)+\alpha_{t}h_{t}(x)\\ \bar{w}_{ti}=e^{-y_{i}h_{t}(x_{i})}
$$
将第一个式子两边同乘-$y_{i}$，并作为e的指数即可得到下一轮$\bar{w}_{t+1,i}$的更新公式：



$$
\bar{w}_{t+1,i}=\bar{w}_{t,i}e^{-y_{i}\alpha_{t}h_{t}(x)}
$$


上式再在分母添加一个规范化因子即为例子中所用到的D_{t}的更新公式。

#### 总结

在训练过程中，每个新的模型都会基于前一个模型的表现结果进行调整，这也就是为什么AdaBoost是自适应（adaptive）的原因，即AdaBoost可以自动适应每个基学习器的准确率。

#### GBDT

- 简介
  GBDT即梯度提升树，提升方法依然采用的是加法模型与前向分布算法。以决策树为基函数的提升方法称为提升树。对分类问题决策树是二叉分类树，对回归问题决策树是二叉决策树。例如前文中的例子中所使用的决策树桩即为一个根节点直接连接两个叶节点的简单决策树。
- 与Adboost的区别
  GBDT与Adboost最主要的区别在于两者如何识别模型的问题。Adaboost用错分数据点来识别问题，通过调整错分数据点的权重来改进模型。GBDT通过负梯度来识别问题，通过计算负梯度来改进模型。
- 学习过程
  针对不同问题的提升树学习算法，其主要区别在于使用的损失函数不同。包括用平方误差损失函数的回归问题，是指数损失函数的分类问题，以及用一般损失函数的一般决策问题。对于分类问题，GBDT实质是把它转化为回归问题。在多分类问题中，假设有k个类别，那么每一轮迭代实质是构建了k棵树，对某个样本x的预测值为



$$
f_{1}(x),f_{2}(x),...,f_{k}(x)
$$


之后使用softmax可以得到属于每一个类别的概率，此时该样本的loss即可以用logitloss来表示，并对所有类别的f(x)都可以算出一个梯度，即可以计算出当前轮的残差，供下一轮迭代学习。下面主要对回归问题的提升树进行说明。

依然采用前向分步算法，过程如下：

第一个式子首先定义初始提升树$f_{0}(x)=0$；之后第m步的模型即为第二个式子，其中$T(x;\Theta)$表示决策树，$\Theta$为决策树的参数；第三个式子表示GBDM的最终模型，其中M为树的个数。
$$
f_{0}(x)=0\\f_{m}(x)=f_{m-1}(x)+T(x;\Theta), m=1,2,...,M\\f_{M}(x)=\sum_{m=1}^{M}T(x;\Theta_{m})
$$
第一个式子首先定义初始提升树$f_{0}(x)=0$；之后第m步的模型即为第二个式子，其中$T(x;\Theta)$表示决策树，$\Theta$为决策树的参数；第三个式子表示GBDM的最终模型，其中M为树的个数。

在前向分步算法的第m步，给定当前模型$f_{m-1}(x)$，需求解
$$\hat{\Theta}_{m}=\underset{\Theta_{m}}{arg\ min}\sum_{i=1}^{N}L(y_{i},f_{m-1}(x_{i})+T(x_{i};\Theta_{m}))$$
得到的$\hat{\Theta}_{m}$即为第m颗树的参数。当采用平方误差作为损失函数时：
$$L(y,f(x))=(y-f(x))^{2}$$
带入上式中，则其损失函数变为：
$$L(y,f_{m-1}(x)+T(x;\Theta_{m}))\\
=[y-f_{m-1}(x)-T(x;\Theta_{m})]^{2}\\
=[r-T(x;\Theta_{m})]^{2}$$
这里
$$r=y-f_{m-1}(x)$$
是当前模型拟合数据的残差。所以，对于回归问题的提升树算法来说，只需简单地拟合当前模型的残差。即每一轮产生的残差作为下一轮回归树的输入，下一轮的回归树的目的就是尽可能的拟合这个输入残差。

- 举例
  我们以简单的年龄预测为例，训练集共包括4个人：A,B,C,D，他们的年龄分别是14，16，24，26。每个人都有两个属性：每周的购物金额、每周的上网时间。数据集如下：

  - A：购物金额<=1K，上网时间<=20h
  - B：购物金额<=1K，上网时间>=20h
  - C：购物金额>=1K，上网时间<=20h
  - D：购物金额>=1K，上网时间>=20h

  我们的目的就是构建一个GBDT模型来预测年龄。简单起见，我们限定每棵树只有一个分支，如下图所示：
  ![GBDT举例](https://raw.githubusercontent.com/shuxunsohu/markdown_pic/master/GBDT.png)

  - 第一轮（树）
    第一颗树节点属性的选取我们用最小化残差的方法。当选择每周购物金额作为划分属性时，两边叶子节点的残差和为：



$$
(14-\frac{14+16}{2})^2+(16-\frac{14+16}{2})^2+\\ (24-\frac{24+26}{2})^2+(26-\frac{24+26}{2})^2=4
$$


当选择上网时间作为划分属性时，得到的残差和为：



$$
(14-\frac{14+24}{2})^{2}+(24-\frac{14+24}{2})^{2}+\\ (16-\frac{16+26}{2})^{2}+(16-\frac{16+26}{2})^{2}=100
$$


通过比较上边两种方法，我们选择每周的购物金额作为划分属性，结果如上图左边的树。此时可以看到A、B被划分到了左节点。左节点的均值为(14+16)/2=15，则A的残差为14-15=-1，B的残差为16-15=1，同理可得C和D的残差分别为-1和1。这样当4个样本经过第一颗树后，分别产生的残差为（-1，1，-1，1），这个残差作为第二课树的输入，如上图右边第二颗树的根节点。

- 第二轮（树）
  第二颗树的目的是尽量去拟合由第一颗树产生的残差（-1，1，-1，1），特征选取的过程同第一棵树，不再复述。现在我们用每周的上网时间来作为划分的属性，则结果如上图第二颗树。A、C被划分到左节点，B、D被划分到右节点，两个节点的均值分别为-1和1。此时两个子节点的残差都为0，训练结束。
- 结果
  不考虑泛化性，我们简单地使用训练集进行测试。
  A = 15 + (–1) = 14
  B = 15 + 1 = 16
  C = 25 + (–1) = 24
  D = 25 + 1 = 26
  全部预测正确，厉(fei)害(hua)了我的哥。
- 总结
  - GBDT每一轮训练时所关注的重点是本轮产生结果的残差，下一轮以本轮残差作为输入，尽量去拟合这个残差，使下一轮输出的残差不断变小。所以GBDT可以做到每一轮一定向损失函数减小的梯度方向变化，而传统的boosting算法只能是尽量向梯度方向减小，这是GBDT与传统boosting算法最大的区别，这也是为什么GBDT相比传统boosting算法可以用更少的树个数与深度达到更好的效果。
  - 和AdaBoost一样，Gradient Boosting也是重复选择一个表现一般的模型并且每次基于先前模型的表现进行调整。不同的是，AdaBoost是通过提升错分数据点的权重来定位模型的不足，而GBDT是通过算梯度来定位模型的不足。因此相比AdaBoost，GBDT可以使用更多种类的目标函数。
  - 抽象地说，模型的训练过程是对一任意可导目标函数的优化过程，通过反复地选择一个指向负梯度方向的函数，该算法可被看作在函数空间里对目标函数进行优化。
  - 回归问题
    1. 用回归树去拟合残差，其实就是用回归树去拟合目标方程关于f（x）的梯度。
    2. 回归的目标函数并不一定会用square loss。square loss的优点是便于理解和实现，缺点在于对于异常值它的鲁棒性较差，一个异常值造成的损失由于二次幂而被过分放大，会影响到最后得到模型在测试集上的表现。可以算则Absolute loss或者Huber loss代替。
  - 分类问题
    1. 此时的目标函数常用log loss，如KL-散度或者交叉熵。
    2. 除了损失函数的区别外，分类问题和回归问题的区别还在于当多分类问题时，每轮可能会训练多个分类器。
  - 由于决策树是非线性的，并且随着深度的加深，非线性越来越强，所以基于决策树的GBDT也是非线性的。

#### xgboost

- 简介
  xgboost 的全称是eXtreme Gradient Boosting，由华盛顿大学的陈天奇博士提出，在Kaggle的希格斯子信号识别竞赛中使用，因其出众的效率与较高的预测准确度而引起了广泛的关注。
- 与Adboost的区别
  GBDT算法只利用了一阶的导数信息，xgboost对损失函数做了二阶的泰勒展开，并在目标函数之外加入了正则项对整体求最优解，用以权衡目标函数的下降和模型的复杂程度，避免过拟合。所以不考虑细节方面，两者最大的不同就是目标函数的定义，接下来就着重从xgboost的目标函数定义上来进行介绍。
- 目标函数
  xgboost的目标函数定义如下：



$$
Obj^{(t)}=\sum_{i=1}^{n}l(y_{i},\hat{y}_{i}^{(t)})+\sum_{i=1}^{t}\Omega(f_{i})\\ =\sum_{i=1}^{n}l(y_{i},\hat{y}_{i}^{(t-1)}+f_{t}(x_{i}))+\Omega(f_{t})+constant
$$


其中，t表示第t轮，$f_{t}$表示第t轮所生成的树模型，$\Omega(f_{i})$表示正则项，$constant=\sum_{i=1}^{t-1}\Omega(f_{i})$。接下来是xgboost的重点，我们使用泰勒展开



$$
f(x+\bigtriangleup x)\simeq f(x)+f^{'}(x)\bigtriangleup x+ \frac{1}{2}f^{''}(x)\bigtriangleup x^{2}
$$


来定义一个近似的目标函数如下：



$$
Obj^{(t)}\simeq \sum_{i=1}^{n}[l(y_{i},\hat y_{i}^{(t-1)})+g_{i}f_{t}(x_{i})+\frac{1}{2}h_{i}f_{t}^{2}(x_{i})]+\Omega(f_{t})+constant\\ g_{i}=\partial _{\hat y(t-1)}l(y_{i},\hat y^{t-1}),h_{i}=\partial _{\hat y(t-1)}^{2}l(y_{i},\hat y^{t-1})
$$
因为l(y_{i},\hat y_{i}^{(t-1)})的值由之前的过程决定，所以本轮不变，constant也不影响本轮的训练，所以将这两者其去掉，得到：



$$
Obj^{(t)}\simeq \sum_{i=1}^{n}[g_{i}f_{t}(x_{i})+\frac{1}{2}h_{i}f_{t}^{2}(x_{i})]+\Omega(f_{t})
$$


现在的目标函数有一个非常明显的特点，它只依赖于每个数据点在误差函数上的一阶导数和二阶导数。接下来，我们对f_{t}的定义做一下细化，将树拆分成结构部分q和叶子权重部分w：



$$
f_{t}(x)=w_{q}(x)
$$


当我们给定了如上定义之后，就可以对树的复杂度$\Omega(f_{t})$进行定义了：



$$
\Omega(f_{t})=\gamma T+\frac{1}{2}\lambda \sum_{j=1}^{T}w_{j}^{2}
$$

其中，第一部分中的T为叶子的个数，第二部分为w的L2模平方。我们来看下图的示例：
![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/04.png)
可以看到叶子的权重w就是GBDT例子中叶子结点的值，而q就是将某个样本点映射到某个叶子结点的函数。有了上边的两个式子后，继续对目标函数进行如下改写：



$$
Obj^{(t)}\simeq \sum_{i=1}^{n}[g_{i}f_{t}(x_{i})+\frac{1}{2}h_{i}f_{t}^{2}(x_{i})]+\Omega(f_{t})\\ =\sum_{i=1}^{n}[g_{i}w_{q}(x_{i})+\frac{1}{2}h_{i}w_{q}^{2}(x_{i})]+\gamma T+\frac{1}{2}\lambda \sum_{j=1}^{T}w_{j}^{2}\\ =\sum_{j=1}^{T}[(\sum_{i\subset I_{j}}g_{i})w_{j}+\frac{1}{2}(\sum_{i\subset I_{j}}h_{i}+\lambda)w_{j}^{2}]+\gamma T
$$


其中，$I_{j}$为每个叶子节点上的样本集合$I_{j}=\{i|q(x_{i}=j\}$。现在这个目标函数包含了T个相互独立的单变量二次函数，我们定义：



$$
G_{i}=\sum_{i\subset I_{j}}g_{i},\ H_{j}=\sum_{i\subset I_{j}}h_{i}
$$
那么我们就得到了最终的目标函数样子：



$$
Obj^{(t)}=[G_{j}w_{j}+\frac{1}{2}(H_{j}+\lambda)w_{j}^{2}]+\gamma T
$$
现在我们假设q已知，通过将上式对w求导并令其等于0，就可以求出令Obj^{(t)}最小的w：



$$
w_{j}^{*}=-\frac{G_{j}}{H_{j}+\lambda}
$$


剩下的工作就很简单了，通过改变树的结构来找到最小的$w_{j}^{*}$，而对应的结构就是我们所需要的结果。不过枚举所有树的结构不太可行，所以常用的是贪心法，每一次尝试去对已有的叶子加入一个分割。对于一个具体的分割方案，我们可以获得的增益可以由如下公式计算：



$$
Gain=\frac{1}{2}[\frac{G_{L}^{2}}{H_{L}+\lambda}+\frac{G_{R}^{2}}{H_{R}+\lambda}-\frac{G_{L}^{2}+G_{R}}{H_{L}+H_{R}+\lambda}]-\gamma
$$


观察这个目标函数会发现如下三点：

- 这个公式形式上跟ID3算法（采用entropy计算增益） 、CART算法（采用gini指数计算增益） 是一致的，都是用分裂后的某种值减去分裂前的某种值，从而得到增益
- 引入分割不一定会使情况变好，因为最后有一个新叶子的惩罚项。所以这也体现了预减枝的思想，即当引入的分割所带来的增益小于一个阈值时，就剪掉这个分割
- 上式中还有一个系数\lambda，是正则项里w的L2模平方的系数，对w做了平滑，也起到了防止过拟合的作用，这个是传统GBDT里不具备的特性
- 总结
  xgboost与传统的GBDT相比，对代价函数进行了二阶泰勒展开，同时用到了一阶与二阶导数，而GBDT在优化时只用到一阶导数的信息，个人认为类似牛顿法与梯度下降的区别。另一方面，xgboost在损失函数里加入的正则项可用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性。

#### **多树的提升方法**

**提升树 boosting tree**

以决策树为基学习器的提升方法称为**提升树**，提升树可以解决分类和回归问题，分类问题以分类树为基学习器，回归问题以回归树为基学习器，决策树均为二叉树。

**提升树模型**可以表示为

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/05.png)

M为决策树个数，$T(x, θ)$ 为决策树模型， θ为决策树参数

 

**提升树算法**采用前向分步算法，初始提升树 f0(x)=0，第m步提升树

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/06.png)

$f_{m-1}(x)$ 是当前模型，相当于是个已知数，模型误差可以表示为

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/07.png)

由于 $f_{m-1}(x)$ 是个常数，y也是常数，最小化误差就是求 T(x, θ) 中的 最优θ，也就是只求第 m 步的最佳模型，所以是一种贪心算法。

 

不同类型的提升树有不同的**损失函数**，回归问题就是均方误差，分类问题为指数损失函数

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/08.png)

 当yy相同时，损失函数趋近于0

 

**回归提升树**

由于分类树比较常见，所以这里主要讲回归问题。

 

**回归树**

假设数据样本为

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/09.png)

，x为输入空间，输入空间为实数域，　【回归问题中 x 一般为连续值，处理方式类似于决策树处理连续值】

将 x 划分成 J 个互不相交的区域，R1、R2、R3...RJ，每个区域的输出为 cj，决策树可表示为

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/10.png)

 

具体理解如图

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/11.png)

可以看到 J 就是叶节点的个数，也表示了决策树的复杂度，只分裂一次的树称为 树桩

 

**回归提升树**

依然采用前向分步算法

1. 初始提升树 f0(x)=0

2. 第 m 步训练决策树 T(x, θ)，得到该步的提升树

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/12.png)

需要最优化 θ

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/13.png)

 

回归问题损失函数为 均方差

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/14.png)

r 就是当前模型的残差，所以 提升树 只需学习当前模型的残差，这使得算法变得简单。

1. 输出组合模型

 

**回归提升树算法总结**

输入：

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/15.png)

输出：

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/16.png)

1）初始提升树 f0(x)=0

2）对 m = 1,2,3...M

3）计算残差 r= yi - fm-1(x)

4）拟合fm-1的残差 r 学习一个回归树 T(x, θ)　　　　【注意，每步要更新 f(x)，f(x)是前n步的和，而不是计算单步的残差，损失】

5）更新

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/17.png)

6）输出回归提升树

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/18.png)

 

**实例**

| x    | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| y    | 5.56 | 5.70 | 5.91 | 6.40 | 6.80 | 7.05 | 8.90 | 8.70 | 9.00 | 9.05 |

以树桩作为基学习器。

1. 求 T1(x) ====> 将样本集按x分成2分，分别求平均即可，那如何分呢？

目标函数为 

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/19.png)

 当 x 属于 R1时，y_predict = c1，误差 y-c1，同理，最终得到上面的损失函数，当损失函数最小时，其对应的划分方式就是最佳划分方式。

 

下面就是按决策树处理连续值的方式

划分点s为 [1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5]

R1 = {x|x<s}；R2={x|x>s}

对叶子结点求平均即可求得 c1，c2

经计算，当 s = 1.5 时，c1 = 5.56，c2 = 7.50，

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/20.png)

同理可得到所有划分的损失

| s    | 1.5   | 2.5   | 3.5  | 4.5  | 5.5  | 6.5  | 7.5  | 8.5   | 9.5   |      |
| ---- | ----- | ----- | ---- | ---- | ---- | ---- | ---- | ----- | ----- | ---- |
| m(s) | 15.72 | 12.07 | 8.36 | 5.78 | 3.91 | 1.93 | 8.01 | 11.73 | 15.74 |      |

可见，当 s = 6.5 时，损失最小，为1.93，此时 c1 = 6.24，c2 = 8.91，回归树为

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/21.png)

 

*当前残差*

| x    | 1     | 2     | 3     | 4    | 5    | 6    | 7     | 8     | 9    | 10   |
| ---- | ----- | ----- | ----- | ---- | ---- | ---- | ----- | ----- | ---- | ---- |
| y    | -0.68 | -0.54 | -0.33 | 0.16 | 0.56 | 0.81 | -0.01 | -0.21 | 0.09 | 0.14 |

*当前损失*

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/22.png)

 

*第一步只是个弱学习器，可见效果不怎么地*

 

1. 求 T2(x) ====> 此时只需学习 T1(x) 的残差

方法同第一步，回归树为

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/23.png)

 

*当前损失*

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/24.png)

 损失为 0.79，比1.93要小。

 

1. 继续求 Tm(x) ====> 此时只需学习 fm-1(x) 的残差

比如学习 6 个回归树，则最终模型为

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/25.png)

 损失为 0.17，比之前要小很多。

 

**现在我们需要考虑几个问题**

1. 上述基学习器 只是 一层，如果是2层、3层，那么基学习器如何表示？会相当麻烦

2. 多层的基学习器又如何相加呢？更麻烦

3. 提升树的基学习器通过最小化均方差来学习，如果损失函数不是 均方差，又如何？

为了解决上述问题，有人提出了改进算法。

 

**梯度提升树 GBDT**

GBDT 也可以解决回归和分类问题，有些地方把 回归 GBDT 叫做 GBRT。

GBDT 损失函数可以有多种，在 sklearn 中，回归问题损失函数有4种：ls 平方损失，lad 绝对损失，huber huber损失，quantile：分位数损失，分类问题损失函数有2种：exponential 指数损失，deviance 对数损失

 

GBDT 利用梯度下降的近似方法，其 *关键是利用 损失函数的负梯度 在当前模型的值 作为 回归提升树中残差的近似*。

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/26.png)

第 m 轮第 i 个样本的损失函数的负梯度，得到 (xi，rmi) 作为新数据，拟合一个回归树

 

**具体算法如下**

输入：

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/27.png)

，损失函数 L(y，f(x))

输出：回归树组合模型F(x)

1）初始化提升树 ====> 估计一个使得损失函数最小的常数c，他只有根节点，如果loss是mes，一般取均值，如果loss是绝对损失，一般取中位数

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/28.png)

2）for m = 1,2...M ====> 训练M个基学习器

3）for i = 1,2...N ====> 遍历N个样本，计算残差　　【为什么带负号，因为f(x)是自变量，在损失函数中它前面有个减号，求导时相当于复合函数，得乘以-1，前面带个负号，刚好和这个-1抵消，r=y-f(x)】

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/27_b.png)

4）拟合一棵cart树，对x进行划分，建立决策树，得到第m棵树的叶节点区域 Rmj，j=1,2..J （j表示叶节点的个数）

5）for j=1,2...J ====> 遍历 J 个叶节点，利用线性搜索，估计每个叶节点的值，使得损失函数最小化　　

c=βf(x)，决策树只是输出了 f(x)，但是 β 是多少，需要根据 min loss 求解，最终把 c 作为叶子结点的输出

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/29.png)

6）更新模型

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/30.png)

7）输出回归树

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/31.gif)

 

**实例**

数据如下：5个样本，4个训练，1个测试，特征为年龄、体重，标签为身高

| 编号 | 年龄(岁) | 体重（kg） | 身高(m)(标签值) |
| ---- | -------- | ---------- | --------------- |
| 0    | 5        | 20         | 1.1             |
| 1    | 7        | 30         | 1.3             |
| 2    | 21       | 70         | 1.7             |
| 3    | 30       | 60         | 1.8             |
| 4    | 25       | 65         | 预测            |

参数设置

迭代次数：n_trees = 5

树的深度：max_depth = 3

学习率：lr = 0.1

损失函数：mes

1. 初始化提升树 ，loss为mes，取均值即可 f0(x) = 1.475

也可以正规求，估计一个使得损失函数最小的常数，loss = Σ(y_true - y_pred)2，要最小，求导，Σ(y_true - y_pred)=Σy_true - Σy_pred=Σy_true - Ny_pred

令导数等于0，y_pred = Σy_true / N，即均值

2. 计算 f0(x) 的近似残差

| **编号** | **真实值** | **f0(x)** | **残差** |
| -------- | ---------- | --------- | -------- |
| 0        | 1.1        | 1.475     | -0.375   |
| 1        | 1.3        | 1.475     | -0.175   |
| 2        | 1.7        | 1.475     | 0.225    |
| 3        | 1.8        | 1.475     | 0.325    |

此时残差变成了真实的标签

3. 基于特征的划分

| 划分点 | 小于划分点的样本 | 大于等于划分点的样本 | SSElSSSEl | SErSEr | SEsumSEsum |
| ------ | ---------------- | -------------------- | --------- | ------ | ---------- |
| 年龄5  | /                | 0，1，2，3           | 0         | 0.327  | 0.327      |
| 年龄7  | 0                | 1，2，3              | 0         | 0.140  | 0.140      |
| 年龄21 | 0，1             | 2，3                 | 0.020     | 0.005  | 0.025      |
| 年龄30 | 0，1，2          | 3                    | 0.187     | 0      | 0.187      |
| 体重20 | /                | 0，1，2，3           | 0         | 0.327  | 0.327      |
| 体重30 | 0                | 1，2，3              | 0         | 0.140  | 0.140      |
| 体重60 | 0，1             | 2，3                 | 0.020     | 0.005  | 0.025      |
| 体重70 | 0，1，3          | 2                    | 0.260     | 0      | 0.260      |

损失函数是mes，我们这里简单计算每个叶节点的平方和损失，上图第4列是左节点的损失，第5列是右节点的损失，以年龄7为例，右节点损失计算如下

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/32.png)

误差最小为0.025，有两种划分方式，随便选一种，年龄21，做如下划分

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/33.png)

 max_depth 为3，还需继续划分，同理可得

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/34.png)

 

4）计算叶节点的值　　　　　　　　【关键点】

遍历叶节点，线性搜索，计算节点值，使得损失函数最小

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/35.png)

r 其实就是基学习器，f0(x) 是之前基学习的和，f0(x)+r 就是本次预测，yi为真实值，最初的真实值

相当于给节点找一个参数r，使得损失函数最小，方法是求导，令导数等于0，计算可得

 

r11 = -0.375，r12 = -0.175，r21 = 0.225，r22 = 0.325

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/36.png)

 

5）更新模型

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/37.jpeg)

6）重复上述步骤即可

 

 

**注意**

1. 提升树的基学习器只能是 cart 树

2. 加法模型可以带学习率，放慢学习速度，防止过拟合

引用链接：https://www.cnblogs.com/yanshw/p/11096164.html

### **stacking/blending**

- **概念**

Stacking模型本质上是一种分层的结构，这里简单起见，只分析二级Stacking。假设我们有3个基模型M1、M2、M3。

\1. 基模型M1，对训练集train训练，然后用于预测train和test的标签列，将预测的训练集和测试集的结果（**即预测出的y**）分别作为P1，T1

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/38.jpeg)

对于M2和M3，重复相同的工作，这样也得到P2，T2，P3，T3。

\2. 分别把P1，P2，P3以及T1，T2，T3合并，得到一个新的训练集和测试集train2，test2.

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/39.jpeg)

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/39_b.jpeg)



\3. 再用第二层的模型M4训练train2，预测test2，得到最终的标签列。必须要注意的是，也是我一开始有点懵的地方。train2和test2里的特征其实是在第一层预测出的y的结果。

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/40.jpeg)

Stacking本质上就是这么直接的思路，但是这样肯定是不行的，问题在于P1的得到是有问题的，用整个训练集训练的模型反过来去预测训练集的标签，毫无疑问过拟合是非常非常严重的，因此现在的问题变成了**如何在解决过拟合的前提下得到P1、P2、P3**，这就变成了熟悉的节奏——K折交叉验证。我们以2折交叉验证得到P1为例，假设训练集为4行3列

将其划分为2部分

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/42.jpeg)

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/41.jpeg)

用traina训练模型M1，然后在trainb上进行预测得到preb3和pred4

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/43.jpeg)

在trainb上训练模型M1，然后在traina上进行预测得到pred1和pred2

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/44.jpeg)

然后把两个预测集进行拼接

![img](https://github.com/makeittrue/data-mining_learning_note/blob/master/Task05/images/45.jpeg)

对于测试集T1的得到，有两种方法。注意到刚刚是2折交叉验证，M1相当于训练了2次，所以一种方法是每一次训练M1，可以直接对整个test进行预测，这样2折交叉验证后测试集相当于预测了2次，然后对这两列求平均得到T1（接下来的代码是这么做的）。或者直接对测试集只用M1预测一次直接得到T1。

P1、T1得到之后，P2、T2、P3、T3也就是同样的方法。理解了2折交叉验证，对于K折的情况也就理解也就非常顺利了。所以最终的代码是两层循环，**第一层循环控制基模型的数目，每一个基模型要这样去得到P1，T1，第二层循环控制的是交叉验证的次数K，对每一个基模型，会训练K次最后拼接得到P1，取平均得到T1**。这下再把[@Wille博文](https://link.zhihu.com/?target=https%3A//dnc1994.com/2016/04/rank-10-percent-in-first-kaggle-competition/)中的那张图片放出来就很容易看懂了。

该图是一个基模型得到P1和T1的过程，采用的是5折交叉验证，所以循环了5次，拼接得到P1，测试集预测了5次，取平均得到T1。而这仅仅只是第二层输入的一列/一个特征，并不是整个训练集。再分析接下来的代码也就很清楚了。也就是刚刚提到的两层循环。

**Note:**

*（1）*一个基模型通过交叉验证训练得到的P1（

![img](https://www.zhihu.com/equation?tex=%5Chat%7By%7D)

） 只是train2中的一列特征，对测试集预测的结果T1只是test2中的一列特征。

*（2）*对于得到的训练集train2，在第二层M4训练的时候，它的标签还是原来的y。

- **python实现**

[Stacking代码](https://link.zhihu.com/?target=https%3A//github.com/InsaneLife/MyPicture/blob/master/ensemble_stacking.py)

该代码完全实现了上面的逻辑，通俗易懂。稍加改造就可以应用于自己的模型。

**Blending**

- **概念**

Blending与Stacking大致相同，只是Blending的主要区别在于训练集不是通过K-Fold的CV策略来获得预测值从而生成第二阶段模型的特征，而是建立一个Holdout集。简单来说，Blending直接用不相交的数据集用于不同层的训练。

以两层的Blending为例，训练集划分为两部分（d1，d2），测试集为test。

1. 第一层：用d1训练多个模型，将其对d2和test的预测结果作为第二层的New Features。
2. 第二层：用d2的New Features和标签训练新的分类器，然后把test的New Features输入作为最终的测试集，对test预测出的结果就是最终的模型融合的值。

- **python实现**

[Blending代码](https://link.zhihu.com/?target=https%3A//github.com/InsaneLife/MyPicture/blob/master/ensemble_blending.py)

**Stacking和Blending对比**

Blending的优点在于：

1.比stacking简单（因为不用进行k次的交叉验证来获得stacker feature）

2.避开了一个信息泄露问题：generlizers和stacker使用了不一样的数据集

3.在团队建模过程中，不需要给队友分享自己的随机种子

而缺点在于：

1.使用了很少的数据（是划分hold-out作为测试集，并非cv）

2.blender可能会过拟合（其实大概率是第一点导致的）

3.stacking使用多次的CV会比较稳健

对于实践中的结果而言，stacking和blending的效果是差不多的，所以使用哪种方法都没什么所谓，完全取决于个人爱好。

参考链接：https://zhuanlan.zhihu.com/p/42229791

**构建多层模型，并利用预测结果再拟合预测**

总结：

比赛的模型融合这个问题，其实涉及多个层面，也是提分和提升模型鲁棒性的一种重要方法：

- 1）**结果层面的融合**，这种是最常见的融合方法，其可行的融合方法也有很多，比如根据结果的得分进行加权融合，还可以做Log，exp处理等。在做结果融合的时候，有一个很重要的条件是模型结果的得分要比较近似，然后结果的差异要比较大，这样的结果融合往往有比较好的效果提升。
- 2）**特征层面的融合**，这个层面其实感觉不叫融合，准确说可以叫分割，很多时候如果我们用同种模型训练，可以把特征进行切分给不同的模型，然后在后面进行模型或者结果融合有时也能产生比较好的效果。
- 3）**模型层面的融合**，模型层面的融合可能就涉及模型的堆叠和设计，比如加Staking层，部分模型的结果作为特征输入等，这些就需要多实验和思考了，基于模型层面的融合最好不同模型类型要有一定的差异，用同种模型不同的参数的收益一般是比较小的。

参考：[Datewhale模型融合](https://github.com/datawhalechina/team-learning/blob/master/数据挖掘实践（二手车价格预测）/Task5 模型融合.md)

心得： 不要为了刷分而取巧，要真正的得到

